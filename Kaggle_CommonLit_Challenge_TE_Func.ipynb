{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle CommonLit Readability Challenge\n",
    "Functions & Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the word embedding matrix for an excerpt\n",
    "def excerpt_embedding(in_excerpt, return_idx, vec_dim=50):\n",
    "    \n",
    "    nltk_word_tokens = nltk.wordpunct_tokenize(in_excerpt)\n",
    "    word_list_series = pd.Series(nltk_word_tokens)\n",
    "    rm_words = word_list_series.isin(spacy_stopwords)\n",
    "    retain_idx = np.where(~rm_words)[0]\n",
    "    word_list_series_no_stop_words = word_list_series[retain_idx]\n",
    "\n",
    "    num_words = len(retain_idx)\n",
    "#     word_embedding = np.zeros((num_words, 50))\n",
    "    word_embedding = np.zeros((num_words, vec_dim))\n",
    "\n",
    "    for idx in range(num_words):\n",
    "        current_word = word_list_series_no_stop_words.iloc[idx].lower()\n",
    "        try:\n",
    "            current_idx = keyset.index(current_word)\n",
    "            word_embedding[idx, :] = embeddings_dict[keyset[current_idx]]\n",
    "        except ValueError:\n",
    "            blank_var = 0\n",
    "            # print('Missing value = ', current_word)\n",
    "    \n",
    "    # Remove rows with all 0\n",
    "    row_sum = np.sum(word_embedding, axis=1)\n",
    "    non_zero_idx = np.where(row_sum != 0)[0]\n",
    "    word_embedding_mod = word_embedding[non_zero_idx, :].copy()\n",
    "\n",
    "    if return_idx == 0:\n",
    "        return word_embedding_mod.shape[0]\n",
    "    \n",
    "    return word_embedding_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, in_size, hidden_layer_size, output_size):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=in_size, hidden_size=hidden_layer_size, bidirectional=True)\n",
    "        self.L1 = nn.Linear(2*hidden_layer_size, output_size[0])\n",
    "        self.L2 = nn.Linear(output_size[0], output_size[1])\n",
    "        self.L3 = nn.Linear(output_size[1], output_size[2])\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_output, (lstm_hn, lstm_cn) = self.lstm(input_seq)\n",
    "        \n",
    "        # Select the hidden state corresponding to the last element in the word sequence\n",
    "        # Since only one element is selected from the first index, in_matrix is a 2D tensor and not a 3D tensor\n",
    "        in_matrix = lstm_output[-1, :, :] \n",
    "\n",
    "        ffd_step_1 = torch.relu(self.L1(in_matrix))\n",
    "        ffd_step_2 = torch.relu(self.L2(ffd_step_1))\n",
    "        ffd_step_3 = self.L3(ffd_step_2)\n",
    "    \n",
    "        return ffd_step_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key Features\n",
    "# - No positional embedding\n",
    "# - Tranformer + FFN\n",
    "class Transformer_Encoder(nn.Module):\n",
    "    def __init__(self, embed_size, n_heads, n_layers, output_size):\n",
    "        super().__init__()\n",
    "#         self.lstm = nn.LSTM(input_size=in_size, hidden_size=hidden_layer_size, bidirectional=True)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=embed_size, nhead=n_heads)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=n_layers)\n",
    "        self.L1 = nn.Linear(embed_size, output_size[0])\n",
    "        self.L2 = nn.Linear(output_size[0], output_size[1])\n",
    "        self.L3 = nn.Linear(output_size[1], output_size[2])\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        trf_output = self.transformer_encoder(input_seq)\n",
    "        in_matrix = torch.mean(trf_output, 0) # Average over all the words for each batch and embedding combination\n",
    "        \n",
    "        ffd_step_1 = torch.relu(self.L1(in_matrix))\n",
    "        ffd_step_2 = torch.relu(self.L2(ffd_step_1))\n",
    "        ffd_step_3 = self.L3(ffd_step_2)\n",
    "    \n",
    "        return ffd_step_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key Features\n",
    "# - No positional embedding\n",
    "# - Tranformer with no FFN\n",
    "class Transformer_Encoder_Self_Decoder(nn.Module):\n",
    "    def __init__(self, embed_size, n_heads, n_layers, output_size):\n",
    "        super().__init__()\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=embed_size, nhead=n_heads)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=n_layers)\n",
    "        self.L1 = nn.Linear(embed_size, output_size[2])\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        trf_output = self.transformer_encoder(input_seq)\n",
    "        in_matrix = torch.mean(trf_output, 0) # Average over all the words for each batch and embedding combination\n",
    "        ffd_step_1 = self.L1(in_matrix)\n",
    "        return ffd_step_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key Features\n",
    "# - Positional embedding\n",
    "# - Tranformer + FFN\n",
    "class Transformer_Encoder_Pos_Embed(nn.Module):\n",
    "    def __init__(self, embed_size, n_heads, n_layers, output_size, dim_feedfwd=2048):\n",
    "        super().__init__()\n",
    "        self.pos_encoder = PositionalEncoding(embed_size, 0.1)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=embed_size, nhead=n_heads\n",
    "                                                        , dropout=0.1, dim_feedforward=dim_feedfwd)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=n_layers)\n",
    "        self.L1 = nn.Linear(embed_size, output_size[0])\n",
    "        self.L2 = nn.Linear(output_size[0], output_size[1])\n",
    "        self.L3 = nn.Linear(output_size[1], output_size[2])\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        input_seq_pos = self.pos_encoder(input_seq)\n",
    "        trf_output = self.transformer_encoder(input_seq_pos)\n",
    "        in_matrix = torch.mean(trf_output, 0) # Average over all the words for each batch and embedding combination\n",
    "        \n",
    "        ffd_step_1 = torch.relu(self.L1(in_matrix))\n",
    "        ffd_step_2 = torch.relu(self.L2(ffd_step_1))\n",
    "        ffd_step_3 = self.L3(ffd_step_2)\n",
    "    \n",
    "        return ffd_step_3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_3_7",
   "language": "python",
   "name": "python_3_7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
